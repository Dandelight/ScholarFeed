[
  {
    "id": "2512.01149v1",
    "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance",
    "authors": [
      "Krishna Taduri",
      "Shaunak Dhande",
      "Giacinto Paolo",
      "Saggese",
      "Paul Smith"
    ],
    "summary": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01149v1"
  },
  {
    "id": "2512.01148v1",
    "title": "SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models",
    "authors": [
      "Hamza Tahboub",
      "Weiyan Shi",
      "Gang Hua",
      "Huaizu Jiang"
    ],
    "summary": "Understanding social interactions from visual cues is a fundamental challenge for a socially competent AI. While powerful pre-trained vision-language models (VLMs) have shown remarkable general capabilities, they surprisingly struggle to unify and learn multiple social perception tasks simultaneously, often exhibiting negative transfer. We identify that this negative transfer stems from a critical issue we term \"social degradation,\" whereby the general visual-linguistic pre-training process of VLMs impairs the visual encoder's ability to represent nuanced social information. We investigate this behavior further under two lenses: decodability through linear representation probing and compatibility through gradient conflict analysis, revealing that both play a role in the degradation, especially the former, which is significantly compromised in the VLM pre-training process. To address these issues, we propose SocialFusion, a unified framework that learns a minimal connection between a frozen visual encoder and a language model. Compared with existing VLMs, it exhibits positive transfer across all five social tasks, leveraging synergies between them to enhance overall performance and achieves comparable performance to task-specific state-of-the-art models on various benchmarks. Our findings suggest that current VLM pre-training strategies may be detrimental to acquiring general social competence and highlight the need for more socially-aware training paradigms.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01148v1"
  },
  {
    "id": "2512.01127v1",
    "title": "Mode-Conditioning Unlocks Superior Test-Time Scaling",
    "authors": [
      "Chen Henry Wu",
      "Sachin Goyal",
      "Aditi Raghunathan"
    ],
    "summary": "Parallel sampling promises substantial gains in test-time scaling, but its effectiveness is sharply limited by diversity collapse, where models concentrate on a few modes and repeated samples produce the same mistakes. We propose the mode-conditioning (ModC) framework, which explicitly allocates test-time compute across reasoning modes using either specialist models or mode-specific prefixes. ModC consistently improves scaling across controlled graph-search tasks and large-scale reasoning benchmarks, spanning model families and sizes from 0.5B to 7B. On OpenThoughts, fine-tuning Qwen2.5-7B with ModC achieves a 4x efficiency gain over standard training while also improving the maximum attainable Pass@k. We further show that gradient clustering enables ModC without explicit mode labels, yielding up to 10% gains on datasets such as NuminaMath. Finally, we show that ModC improves reinforcement learning (RL) and can further boost diversity-inducing RL methods. These results demonstrate that standard training underutilizes the diversity in data, and that ModC provides a simple, effective remedy for unlocking the full benefits of diversity in test-time scaling.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01127v1"
  },
  {
    "id": "2512.01119v1",
    "title": "World Model Robustness via Surprise Recognition",
    "authors": [
      "Geigh Zollicoffer",
      "Tanush Chopra",
      "Mingkuan Yan",
      "Xiaoxu Ma",
      "Kenneth Eaton",
      "Mark Riedl"
    ],
    "summary": "AI systems deployed in the real world must contend with distractions and out-of-distribution (OOD) noise that can destabilize their policies and lead to unsafe behavior. While robust training can reduce sensitivity to some forms of noise, it is infeasible to anticipate all possible OOD conditions. To mitigate this issue, we develop an algorithm that leverages a world model's inherent measure of surprise to reduce the impact of noise in world model--based reinforcement learning agents. We introduce both multi-representation and single-representation rejection sampling, enabling robustness to settings with multiple faulty sensors or a single faulty sensor. While the introduction of noise typically degrades agent performance, we show that our techniques preserve performance relative to baselines under varying types and levels of noise across multiple environments within self-driving simulation domains (CARLA and Safety Gymnasium). Furthermore, we demonstrate that our methods enhance the stability of two state-of-the-art world models with markedly different underlying architectures: Cosmos and DreamerV3. Together, these results highlight the robustness of our approach across world modeling domains. We release our code at https://github.com/Bluefin-Tuna/WISER .",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01119v1"
  },
  {
    "id": "2512.01113v1",
    "title": "Efficiently Learning Branching Networks for Multitask Algorithmic Reasoning",
    "authors": [
      "Dongyue Li",
      "Zhenshuo Zhang",
      "Minxuan Duan",
      "Edgar Dobriban",
      "Hongyang R. Zhang"
    ],
    "summary": "Algorithmic reasoning -- the ability to perform step-by-step logical inference -- has become a core benchmark for evaluating reasoning in graph neural networks (GNNs) and large language models (LLMs). Ideally, one would like to design a single model capable of performing well on multiple algorithmic reasoning tasks simultaneously. However, this is challenging when the execution steps of algorithms differ from one another, causing negative interference when they are trained together.\n  We propose branching neural networks, a principled architecture for multitask algorithmic reasoning. Searching for the optimal $k$-ary tree with $L$ layers over $n$ algorithmic tasks is combinatorial, requiring exploration of up to $k^{nL}$ possible structures. We develop AutoBRANE, an efficient algorithm that reduces this search to $O(nL)$ time by solving a convex relaxation at each layer to approximate an optimal task partition. The method clusters tasks using gradient-based affinity scores and can be used on top of any base model, including GNNs and LLMs.\n  We validate AutoBRANE on a broad suite of graph-algorithmic and text-based reasoning benchmarks. We show that gradient features estimate true task performance within 5% error across four GNNs and four LLMs (up to 34B parameters). On the CLRS benchmark, it outperforms the strongest single multitask GNN by 3.7% and the best baseline by 1.2%, while reducing runtime by 48% and memory usage by 26%. The learned branching structures reveal an intuitively reasonable hierarchical clustering of related algorithms. On three text-based graph reasoning benchmarks, AutoBRANE improves over the best non-branching multitask baseline by 3.2%. Finally, on a large graph dataset with 21M edges and 500 tasks, AutoBRANE achieves a 28% accuracy gain over existing multitask and branching architectures, along with a 4.5$\\times$ reduction in runtime.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01113v1"
  },
  {
    "id": "2512.01107v1",
    "title": "Foundation Priors",
    "authors": [
      "Sanjog Misra"
    ],
    "summary": "Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.\n  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "econ.EM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01107v1"
  },
  {
    "id": "2512.01105v1",
    "title": "Supporting Productivity Skill Development in College Students through Social Robot Coaching: A Proof-of-Concept",
    "authors": [
      "Himanshi Lalwani",
      "Hanan Salam"
    ],
    "summary": "College students often face academic challenges that hamper their productivity and well-being. Although self-help books and productivity apps are popular, they often fall short. Books provide generalized, non-interactive guidance, and apps are not inherently educational and can hinder the development of key organizational skills. Traditional productivity coaching offers personalized support, but is resource-intensive and difficult to scale. In this study, we present a proof-of-concept for a socially assistive robot (SAR) as an educational coach and a potential solution to the limitations of existing productivity tools and coaching approaches. The SAR delivers six different lessons on time management and task prioritization. Users interact via a chat interface, while the SAR responds through speech (with a toggle option). An integrated dashboard monitors progress, mood, engagement, confidence per lesson, and time spent per lesson. It also offers personalized productivity insights to foster reflection and self-awareness. We evaluated the system with 15 college students, achieving a System Usability Score of 79.2 and high ratings for overall experience and engagement. Our findings suggest that SAR-based productivity coaching can offer an effective and scalable solution to improve productivity among college students.",
    "published": "2025-11-30",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01105v1"
  },
  {
    "id": "2512.01099v1",
    "title": "Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems",
    "authors": [
      "Daria Smirnova",
      "Hamid Nasiri",
      "Marta Adamska",
      "Zhengxin Yu",
      "Peter Garraghan"
    ],
    "summary": "As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01099v1"
  },
  {
    "id": "2512.01097v1",
    "title": "Discriminative classification with generative features: bridging Naive Bayes and logistic regression",
    "authors": [
      "Zachary Terner",
      "Alexander Petersen",
      "Yuedong Wang"
    ],
    "summary": "We introduce Smart Bayes, a new classification framework that bridges generative and discriminative modeling by integrating likelihood-ratio-based generative features into a logistic-regression-style discriminative classifier. From the generative perspective, Smart Bayes relaxes the fixed unit weights of Naive Bayes by allowing data-driven coefficients on density-ratio features. From a discriminative perspective, it constructs transformed inputs as marginal log-density ratios that explicitly quantify how much more likely each feature value is under one class than another, thereby providing predictors with stronger class separation than the raw covariates. To support this framework, we develop a spline-based estimator for univariate log-density ratios that is flexible, robust, and computationally efficient. Through extensive simulations and real-data studies, Smart Bayes often outperforms both logistic regression and Naive Bayes. Our results highlight the potential of hybrid approaches that exploit generative structure to enhance discriminative performance.",
    "published": "2025-11-30",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.CO",
      "stat.ME"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01097v1"
  },
  {
    "id": "2512.01095v1",
    "title": "CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions",
    "authors": [
      "Simon Kohaut",
      "Daniel Ochs",
      "Shun Zhang",
      "Benedict Flade",
      "Julian Eggert",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ],
    "summary": "We present CycliST, a novel benchmark dataset designed to evaluate Video Language Models (VLM) on their ability for textual reasoning over cyclical state transitions. CycliST captures fundamental aspects of real-world processes by generating synthetic, richly structured video sequences featuring periodic patterns in object motion and visual attributes. CycliST employs a tiered evaluation system that progressively increases difficulty through variations in the number of cyclic objects, scene clutter, and lighting conditions, challenging state-of-the-art models on their spatio-temporal cognition. We conduct extensive experiments with current state-of-the-art VLMs, both open-source and proprietary, and reveal their limitations in generalizing to cyclical dynamics such as linear and orbital motion, as well as time-dependent changes in visual attributes like color and scale. Our results demonstrate that present-day VLMs struggle to reliably detect and exploit cyclic patterns, lack a notion of temporal understanding, and are unable to extract quantitative insights from scenes, such as the number of objects in motion, highlighting a significant technical gap that needs to be addressed. More specifically, we find no single model consistently leads in performance: neither size nor architecture correlates strongly with outcomes, and no model succeeds equally well across all tasks. By providing a targeted challenge and a comprehensive evaluation framework, CycliST paves the way for visual reasoning models that surpass the state-of-the-art in understanding periodic patterns.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01095v1"
  },
  {
    "id": "2512.01089v1",
    "title": "CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents",
    "authors": [
      "Peter Jansen",
      "Samiah Hassan",
      "Pragnya Narasimha"
    ],
    "summary": "Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01089v1"
  },
  {
    "id": "2512.01081v1",
    "title": "Testing the Machine Consciousness Hypothesis",
    "authors": [
      "Stephen Fitz"
    ],
    "summary": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "cs.NE",
      "q-bio.NC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01081v1"
  },
  {
    "id": "2512.01078v1",
    "title": "SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds",
    "authors": [
      "Jiawei Ren",
      "Yan Zhuang",
      "Xiaokang Ye",
      "Lingjun Mao",
      "Xuhong He",
      "Jianzhi Shen",
      "Mrinaal Dogra",
      "Yiming Liang",
      "Ruixuan Zhang",
      "Tianai Yue",
      "Yiqing Yang",
      "Eric Liu",
      "Ryan Wu",
      "Kevin Benavente",
      "Rajiv Mandya Nagaraju",
      "Muhammad Faayez",
      "Xiyan Zhang",
      "Dhruv Vivek Sharma",
      "Xianrui Zhong",
      "Ziqiao Ma",
      "Tianmin Shu",
      "Zhiting Hu",
      "Lianhui Qin"
    ],
    "summary": "While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01078v1"
  },
  {
    "id": "2512.01067v1",
    "title": "On The Finetuning of MLIPs Through the Lens of Iterated Maps With BPTT",
    "authors": [
      "Evan Dramko",
      "Yizhi Zhu",
      "Aleksandar Krivokapic",
      "Geoffroy Hautier",
      "Thomas Reps",
      "Christopher Jermaine",
      "Anastasios Kyrillidis"
    ],
    "summary": "Vital to the creation of advanced materials is performing structural relaxations. Traditional approaches built on physics-derived first-principles calculations are computationally expensive, motivating the creation of machine-learning interatomic potentials (MLIPs). Traditional approaches to training MLIPs for structural relaxations involves training models to faithfully reproduce first-principles computed forces. We propose a fine-tuning method to be used on a pretrained MLIP in which we create a fully-differentiable end-to-end simulation loop that optimizes the predicted final structures directly. Trajectories are unrolled and gradients are tracked through the entire relaxation. We show that this method achieves substantial performance gains when applied to pretrained models, leading to a nearly $50\\%$ reduction in test error across the sample datasets. Interestingly, we show the process is robust to substantial variation in the relaxation setup, achieving negligibly different results across varied hyperparameter and procedural modifications. Experimental results indicate this is due to a ``preference'' of BPTT to modify the MLIP rather than the other trainable parameters. Of particular interest to practitioners is that this approach lowers the data requirements for producing an effective domain-specific MLIP, addressing a common bottleneck in practical deployment.",
    "published": "2025-11-30",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01067v1"
  },
  {
    "id": "2512.01062v1",
    "title": "PIANO: Physics-informed Dual Neural Operator for Precipitation Nowcasting",
    "authors": [
      "Seokhyun Chin",
      "Junghwan Park",
      "Woojin Cho"
    ],
    "summary": "Precipitation nowcasting, key for early warning of disasters, currently relies on computationally expensive and restrictive methods that limit access to many countries. To overcome this challenge, we propose precipitation nowcasting using satellite imagery with physics constraints for improved accuracy and physical consistency. We use a novel physics-informed dual neural operator (PIANO) structure to enforce the fundamental equation of advection-diffusion during training to predict satellite imagery using a PINN loss. Then, we use a generative model to convert satellite images to radar images, which are used for precipitation nowcasting. Compared to baseline models, our proposed model shows a notable improvement in moderate (4mm/h) precipitation event prediction alongside short-term heavy (8mm/h) precipitation event prediction. It also demonstrates low seasonal variability in predictions, indicating robustness for generalization. This study suggests the potential of the PIANO and serves as a good baseline for physics-informed precipitation nowcasting.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01062v1"
  },
  {
    "id": "2512.01059v1",
    "title": "Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction",
    "authors": [
      "Anantha Padmanaban Krishna Kumar"
    ],
    "summary": "Although scaling laws and many empirical results suggest that increasing the size of Vision Transformers often improves performance, model accuracy and training behavior are not always monotonically increasing with scale. Focusing on ViT-B/16 trained on ImageNet-1K, we study two simple parameter-reduction strategies applied to the MLP blocks, each removing 32.7\\% of the baseline parameters. Our \\emph{GroupedMLP} variant shares MLP weights between adjacent transformer blocks and achieves 81.47\\% top-1 accuracy while maintaining the baseline computational cost. Our \\emph{ShallowMLP} variant halves the MLP hidden dimension and reaches 81.25\\% top-1 accuracy with a 38\\% increase in inference throughput. Both models outperform the 86.6M-parameter baseline (81.05\\%) and exhibit substantially improved training stability, reducing peak-to-final accuracy degradation from 0.47\\% to the range 0.03\\% to 0.06\\%. These results suggest that, for ViT-B/16 on ImageNet-1K with a standard training recipe, the model operates in an overparameterized regime in which MLP capacity can be reduced without harming performance and can even slightly improve it. More broadly, our findings suggest that architectural constraints such as parameter sharing and reduced width may act as useful inductive biases, and highlight the importance of how parameters are allocated when designing Vision Transformers. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01059v1"
  },
  {
    "id": "2512.01054v1",
    "title": "Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning for DDPMs and VAEs",
    "authors": [
      "MohammadParsa Dini",
      "Human Jafari",
      "Sajjad Amini",
      "MohammadMahdi Mojahedian"
    ],
    "summary": "Machine Unlearning is essential for large generative models (VAEs, DDPMs) to comply with the right to be forgotten and prevent undesired content generation without costly retraining. Existing approaches, such as Static-lambda SISS for diffusion models, rely on a fixed mixing weight lambda, which is suboptimal because the required unlearning strength varies across samples and training stages.\n  We propose Adaptive-lambda SISS, a principled extension that turns lambda into a latent variable dynamically inferred at each training step. A lightweight inference network parameterizes an adaptive posterior over lambda, conditioned on contextual features derived from the instantaneous SISS loss terms (retain/forget losses and their gradients). This enables joint optimization of the diffusion model and the lambda-inference mechanism via a variational objective, yielding significantly better trade-offs.\n  We further extend the adaptive-lambda principle to score-based unlearning and introduce a multi-class variant of Score Forgetting Distillation. In addition, we present two new directions: (i) a hybrid objective combining the data-free efficiency of Score Forgetting Distillation with the direct gradient control of SISS, and (ii) a Reinforcement Learning formulation that treats unlearning as a sequential decision process, learning an optimal policy over a state space defined by the model's current memory of the forget set.\n  Experiments on an augmented MNIST benchmark show that Adaptive-lambda SISS substantially outperforms the original static-lambda SISS, achieving stronger removal of forgotten classes while better preserving generation quality on the retain set.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01054v1"
  },
  {
    "id": "2512.01047v1",
    "title": "Automating the Refinement of Reinforcement Learning Specifications",
    "authors": [
      "Tanmay Ambadkar",
      "Đorđe Žikelić",
      "Abhinav Verma"
    ],
    "summary": "Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \\textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \\textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \\textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \\textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \\textsc{AutoSpec} are utilized.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01047v1"
  },
  {
    "id": "2512.01046v1",
    "title": "Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids",
    "authors": [
      "Hadi Nekoei",
      "Alexandre Blondin Massé",
      "Rachid Hassani",
      "Sarath Chandar",
      "Vincent Mai"
    ],
    "summary": "Reinforcement learning (RL) is a powerful framework for optimizing decision-making in complex systems under uncertainty, an essential challenge in real-world settings, particularly in the context of the energy transition. A representative example is remote microgrids that supply power to communities disconnected from the main grid. Enabling the energy transition in such systems requires coordinated control of renewable sources like wind turbines, alongside fuel generators and batteries, to meet demand while minimizing fuel consumption and battery degradation under exogenous and intermittent load and wind conditions. These systems must often conform to extensive regulations and complex operational constraints. To ensure that RL agents respect these constraints, it is crucial to provide interpretable guarantees. In this paper, we introduce Shielded Controller Units (SCUs), a systematic and interpretable approach that leverages prior knowledge of system dynamics to ensure constraint satisfaction. Our shield synthesis methodology, designed for real-world deployment, decomposes the environment into a hierarchical structure where each SCU explicitly manages a subset of constraints. We demonstrate the effectiveness of SCUs on a remote microgrid optimization task with strict operational requirements. The RL agent, equipped with SCUs, achieves a 24% reduction in fuel consumption without increasing battery degradation, outperforming other baselines while satisfying all constraints. We hope SCUs contribute to the safe application of RL to the many decision-making challenges linked to the energy transition.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01046v1"
  },
  {
    "id": "2512.01045v1",
    "title": "Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal",
    "authors": [
      "Shenxi Liu",
      "Kan Li",
      "Mingyang Zhao",
      "Yuhang Tian",
      "Shoujun Zhou",
      "Bin Li"
    ],
    "summary": "The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \\textbf{\\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01045v1"
  },
  {
    "id": "2512.01038v1",
    "title": "FMTK: A Modular Toolkit for Composable Time Series Foundation Model Pipelines",
    "authors": [
      "Hetvi Shastri",
      "Pragya Sharma",
      "Walid A. Hanafy",
      "Mani Srivastava",
      "Prashant Shenoy"
    ],
    "summary": "Foundation models (FMs) have opened new avenues for machine learning applications due to their ability to adapt to new and unseen tasks with minimal or no further training. Time-series foundation models (TSFMs) -- FMs trained on time-series data -- have shown strong performance on classification, regression, and imputation tasks. Recent pipelines combine TSFMs with task-specific encoders, decoders, and adapters to improve performance; however, assembling such pipelines typically requires ad hoc, model-specific implementations that hinder modularity and reproducibility. We introduce FMTK, an open-source, lightweight and extensible toolkit for constructing and fine-tuning TSFM pipelines via standardized backbone and component abstractions. FMTK enables flexible composition across models and tasks, achieving correctness and performance with an average of seven lines of code. https://github.com/umassos/FMTK",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01038v1"
  },
  {
    "id": "2512.01037v1",
    "title": "When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals",
    "authors": [
      "Riad Ahmed Anonto",
      "Md Labid Al Nahiyan",
      "Md Tanvir Hassan",
      "Ch. Md. Rakin Haider"
    ],
    "summary": "Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01037v1"
  },
  {
    "id": "2512.01035v1",
    "title": "Goal-Oriented Multi-Agent Semantic Networking: Unifying Intents, Semantics, and Intelligence",
    "authors": [
      "Shutong Chen",
      "Qi Liao",
      "Adnan Aijaz",
      "Yansha Deng"
    ],
    "summary": "6G services are evolving toward goal-oriented and AI-native communication, which are expected to deliver transformative societal benefits across various industries and promote energy sustainability. Yet today's networking architectures, built on complete decoupling of the applications and the network, cannot expose or exploit high-level goals, limiting their ability to adapt intelligently to service needs. This work introduces Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet), a new architecture that elevates communication from data exchange to goal fulfilment. GoAgentNet enables applications and the network to collaborate by abstracting their functions into multiple collaborative agents, and jointly orchestrates multi-agent sensing, networking, computation, and control through semantic computation and cross-layer semantic networking, allowing the entire architecture to pursue unified application goals. We first outline the limitations of legacy network designs in supporting 6G services, based on which we highlight key enablers of our GoAgentNet design. Then, through three representative 6G usage scenarios, we demonstrate how GoAgentNet can unlock more efficient and intelligent services. We further identify unique challenges faced by GoAgentNet deployment and corresponding potential solutions. A case study on robotic fault detection and recovery shows that our GoAgentNet architecture improves energy efficiency by up to 99% and increases the task success rate by up to 72%, compared with the existing networking architectures without GoAgentNet, which underscores its potential to support scalable and sustainable 6G systems.",
    "published": "2025-11-30",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01035v1"
  },
  {
    "id": "2512.01034v1",
    "title": "AltNet: Addressing the Plasticity-Stability Dilemma in Reinforcement Learning",
    "authors": [
      "Mansi Maheshwari",
      "John C. Raisbeck",
      "Bruno Castro da Silva"
    ],
    "summary": "Neural networks have shown remarkable success in supervised learning when trained on a single task using a fixed dataset. However, when neural networks are trained on a reinforcement learning task, their ability to continue learning from new experiences declines over time. This decline in learning ability is known as plasticity loss. To restore plasticity, prior work has explored periodically resetting the parameters of the learning network, a strategy that often improves overall performance. However, such resets come at the cost of a temporary drop in performance, which can be dangerous in real-world settings. To overcome this instability, we introduce AltNet, a reset-based approach that restores plasticity without performance degradation by leveraging twin networks. The use of twin networks anchors performance during resets through a mechanism that allows networks to periodically alternate roles: one network learns as it acts in the environment, while the other learns off-policy from the active network's interactions and a replay buffer. At fixed intervals, the active network is reset and the passive network, having learned from prior experiences, becomes the new active network. AltNet restores plasticity, improving sample efficiency and achieving higher performance, while avoiding performance drops that pose risks in safety-critical settings. We demonstrate these advantages in several high-dimensional control tasks from the DeepMind Control Suite, where AltNet outperforms various relevant baseline methods, as well as state-of-the-art reset-based techniques.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01034v1"
  },
  {
    "id": "2512.01031v1",
    "title": "VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference",
    "authors": [
      "Jiaming Tang",
      "Yufei Sun",
      "Yilong Zhao",
      "Shang Yang",
      "Yujun Lin",
      "Zhuoyang Zhang",
      "James Hou",
      "Yao Lu",
      "Zhijian Liu",
      "Song Han"
    ],
    "summary": "Vision-Language-Action models (VLAs) are becoming increasingly capable across diverse robotic tasks. However, their real-world deployment remains slow and inefficient: demonstration videos are often sped up by 5-10x to appear smooth, with noticeable action stalls and delayed reactions to environmental changes. Asynchronous inference offers a promising solution to achieve continuous and low-latency control by enabling robots to execute actions and perform inference simultaneously. However, because the robot and environment continue to evolve during inference, a temporal misalignment arises between the prediction and execution intervals. This leads to significant action instability, while existing methods either degrade accuracy or introduce runtime overhead to mitigate it. We propose VLASH, a general asynchronous inference framework for VLAs that delivers smooth, accurate, and fast reaction control without additional overhead or architectural changes. VLASH estimates the future execution-time state by rolling the robot state forward with the previously generated action chunk, thereby bridging the gap between prediction and execution. Experiments show that VLASH achieves up to 2.03x speedup and reduces reaction latency by up to 17.4x compared to synchronous inference while fully preserving the original accuracy. Moreover, it empowers VLAs to handle fast-reaction, high-precision tasks such as playing ping-pong and playing whack-a-mole, where traditional synchronous inference fails. Code is available at https://github.com/mit-han-lab/vlash",
    "published": "2025-11-30",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01031v1"
  },
  {
    "id": "2512.01025v1",
    "title": "Operator-Theoretic Framework for Gradient-Free Federated Learning",
    "authors": [
      "Mohit Kumar",
      "Mathias Brucker",
      "Alexander Valentinitsch",
      "Adnan Husakovic",
      "Ali Abbas",
      "Manuela Geiß",
      "Bernhard A. Moser"
    ],
    "summary": "Federated learning must address heterogeneity, strict communication and computation limits, and privacy while ensuring performance. We propose an operator-theoretic framework that maps the $L^2$-optimal solution into a reproducing kernel Hilbert space (RKHS) via a forward operator, approximates it using available data, and maps back with the inverse operator, yielding a gradient-free scheme. Finite-sample bounds are derived using concentration inequalities over operator norms, and the framework identifies a data-dependent hypothesis space with guarantees on risk, error, robustness, and approximation. Within this space we design efficient kernel machines leveraging the space folding property of Kernel Affine Hull Machines. Clients transfer knowledge via a scalar space folding measure, reducing communication and enabling a simple differentially private protocol: summaries are computed from noise-perturbed data matrices in one step, avoiding per-round clipping and privacy accounting. The induced global rule requires only integer minimum and equality-comparison operations per test point, making it compatible with fully homomorphic encryption (FHE). Across four benchmarks, the gradient-free FL method with fixed encoder embeddings matches or outperforms strong gradient-based fine-tuning, with gains up to 23.7 points. In differentially private experiments, kernel smoothing mitigates accuracy loss in high-privacy regimes. The global rule admits an FHE realization using $Q \\times C$ encrypted minimum and $C$ equality-comparison operations per test point, with operation-level benchmarks showing practical latencies. Overall, the framework provides provable guarantees with low communication, supports private knowledge transfer via scalar summaries, and yields an FHE-compatible prediction rule offering a mathematically grounded alternative to gradient-based federated learning under heterogeneity.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01025v1"
  },
  {
    "id": "2512.01020v1",
    "title": "Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics",
    "authors": [
      "Jinu Lee",
      "Kyoung-Woon On",
      "Simeng Han",
      "Arman Cohan",
      "Julia Hockenmaier"
    ],
    "summary": "Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01020v1"
  },
  {
    "id": "2512.01017v1",
    "title": "ChartAnchor: Chart Grounding with Structural-Semantic Fidelity",
    "authors": [
      "Xinhang Li",
      "Jingbo Zhou",
      "Pengfei Luo",
      "Yixiong Xiao",
      "Tong Xu"
    ],
    "summary": "Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01017v1"
  },
  {
    "id": "2512.01010v1",
    "title": "Chain of Unit-Physics: A Primitive-Centric Approach to Scientific Code Synthesis",
    "authors": [
      "Vansh Sharma",
      "Venkat Raman"
    ],
    "summary": "Agentic large language models are proposed as autonomous code generators for scientific computing, yet their reliability in high-stakes problems remains unclear. Developing computational scientific software from natural-language queries remains challenging broadly due to (a) sparse representation of domain codes during training and (b) the limited feasibility of RLHF with a small expert community. To address these limitations, this work conceptualizes an inverse approach to code design, embodied in the Chain of Unit-Physics framework: a first-principles (or primitives)-centric, multi-agent system in which human expert knowledge is encoded as unit-physics tests that explicitly constrain code generation. The framework is evaluated on a nontrivial combustion task, used here as a representative benchmark for scientific problem with realistic physical constraints. Closed-weight systems and code-focused agentic variants fail to produce correct end-to-end solvers, despite tool and web access, exhibiting four recurrent error classes: interface (syntax/API) hallucinations, overconfident assumptions, numerical/physical incoherence, and configuration fragility. Open-weight models with chain-of-thought (CoT) decoding reduce interface errors but still yield incorrect solutions. On the benchmark task, the proposed framework converges within 5-6 iterations, matches the human-expert implementation (mean error of $3.1\\times10^{-3}$ %), with a $\\sim$33.4 % faster runtime and a $\\sim$30 % efficient memory usage at a cost comparable to mid-sized commercial APIs, yielding a practical template for physics-grounded scientific code generation. As datasets and models evolve, zero-shot code accuracy will improve; however, the Chain of Unit-Physics framework goes further by embedding first-principles analysis that is foundational to scientific codes.",
    "published": "2025-11-30",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.01010v1"
  },
  {
    "id": "2512.00999v1",
    "title": "Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints",
    "authors": [
      "Mohsin Rasheed",
      "Abdullah Al-Mamun"
    ],
    "summary": "Medical imaging is essential for clinical diagnosis, yet real-world data frequently suffers from corruption, noise, and potential tampering, challenging the reliability of AI-assisted interpretation. Conventional reconstruction techniques prioritize pixel-level recovery and may produce visually plausible outputs while compromising anatomical fidelity, an issue that can directly impact clinical outcomes. We propose a semantic-aware medical image reconstruction framework that integrates high-level latent embeddings with a hybrid U-Net architecture to preserve clinically relevant structures during restoration. To ensure trust and accountability, we incorporate a lightweight blockchain-based provenance layer using scale-free graph design, enabling verifiable recording of each reconstruction event without imposing significant overhead. Extensive evaluation across multiple datasets and corruption types demonstrates improved structural consistency, restoration accuracy, and provenance integrity compared with existing approaches. By uniting semantic-guided reconstruction with secure traceability, our solution advances dependable AI for medical imaging, enhancing both diagnostic confidence and regulatory compliance in healthcare environments.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00999v1"
  },
  {
    "id": "2512.00997v1",
    "title": "IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch",
    "authors": [
      "Param Biyani",
      "Shashank Kirtania",
      "Yasharth Bajpai",
      "Sumit Gulwani",
      "Ashish Tiwari"
    ],
    "summary": "We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \\benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00997v1"
  },
  {
    "id": "2512.00979v1",
    "title": "An Approach to Variable Clustering: K-means in Transposed Data and its Relationship with Principal Component Analysis",
    "authors": [
      "Victor Saquicela",
      "Kenneth Palacio-Baus",
      "Mario Chifla"
    ],
    "summary": "Principal Component Analysis (PCA) and K-means constitute fundamental techniques in multivariate analysis. Although they are frequently applied independently or sequentially to cluster observations, the relationship between them, especially when K-means is used to cluster variables rather than observations, has been scarcely explored. This study seeks to address this gap by proposing an innovative method that analyzes the relationship between clusters of variables obtained by applying K-means on transposed data and the principal components of PCA. Our approach involves applying PCA to the original data and K-means to the transposed data set, where the original variables are converted into observations. The contribution of each variable cluster to each principal component is then quantified using measures based on variable loadings. This process provides a tool to explore and understand the clustering of variables and how such clusters contribute to the principal dimensions of variation identified by PCA.",
    "published": "2025-11-30",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00979v1"
  },
  {
    "id": "2512.00969v1",
    "title": "Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE",
    "authors": [
      "Felix Saretzky",
      "Lucas Andersen",
      "Thomas Engel",
      "Fazel Ansari"
    ],
    "summary": "The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a \"what-if\" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00969v1"
  },
  {
    "id": "2512.00968v1",
    "title": "Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search",
    "authors": [
      "Ziyang Zeng",
      "Heming Jing",
      "Jindong Chen",
      "Xiangli Li",
      "Hongyu Liu",
      "Yixuan He",
      "Zhengyu Li",
      "Yige Sun",
      "Zheyong Xie",
      "Yuqing Yang",
      "Shaosheng Cao",
      "Jun Fan",
      "Yi Wu",
      "Yao Hu"
    ],
    "summary": "Ranking relevance is a fundamental task in search engines, aiming to identify the items most relevant to a given user query. Traditional relevance models typically produce scalar scores or directly predict relevance labels, limiting both interpretability and the modeling of complex relevance signals. Inspired by recent advances in Chain-of-Thought (CoT) reasoning for complex tasks, we investigate whether explicit reasoning can enhance both interpretability and performance in relevance modeling. However, existing reasoning-based Generative Relevance Models (GRMs) primarily rely on supervised fine-tuning on large amounts of human-annotated or synthetic CoT data, which often leads to limited generalization. Moreover, domain-agnostic, free-form reasoning tends to be overly generic and insufficiently grounded, limiting its potential to handle the diverse and ambiguous cases prevalent in open-domain search. In this work, we formulate relevance modeling in Xiaohongshu search as a reasoning task and introduce a Reinforcement Learning (RL)-based training framework to enhance the grounded reasoning capabilities of GRMs. Specifically, we incorporate practical business-specific relevance criteria into the multi-step reasoning prompt design and propose Stepwise Advantage Masking (SAM), a lightweight process-supervision strategy which facilitates effective learning of these criteria through improved credit assignment. To enable industrial deployment, we further distill the large-scale RL-tuned model to a lightweight version suitable for real-world search systems. Extensive experiments on industrial datasets, along with online A/B tests, demonstrate the effectiveness of our approach.",
    "published": "2025-11-30",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00968v1"
  },
  {
    "id": "2512.00949v1",
    "title": "Multi-Modal AI for Remote Patient Monitoring in Cancer Care",
    "authors": [
      "Yansong Liu",
      "Ronnie Stafford",
      "Pramit Khetrapal",
      "Huriye Kocadag",
      "Graça Carvalho",
      "Patricia de Winter",
      "Maryam Imran",
      "Amelia Snook",
      "Adamos Hadjivasiliou",
      "D. Vijay Anand",
      "Weining Lin",
      "John Kelly",
      "Yukun Zhou",
      "Ivana Drobnjak"
    ],
    "summary": "For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop)",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00949v1"
  },
  {
    "id": "2512.00947v1",
    "title": "Table as a Modality for Large Language Models",
    "authors": [
      "Liyao Li",
      "Chao Ye",
      "Wentao Ye",
      "Yifei Sun",
      "Zhe Jiang",
      "Haobo Wang",
      "Jiaming Tian",
      "Yiming Zhang",
      "Ningtao Wang",
      "Xing Fu",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "summary": "To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose TAMO, which bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements on generalization with an average relative gain of 42.65%.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00947v1"
  },
  {
    "id": "2512.00946v1",
    "title": "Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data",
    "authors": [
      "Alvaro Paredes Amorin",
      "Andre Python",
      "Christoph Weisser"
    ],
    "summary": "Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00946v1"
  },
  {
    "id": "2512.00939v1",
    "title": "Constant-Time Motion Planning with Manipulation Behaviors",
    "authors": [
      "Nayesha Gandotra",
      "Itamar Mishani",
      "Maxim Likhachev"
    ],
    "summary": "Recent progress in contact-rich robotic manipulation has been striking, yet most deployed systems remain confined to simple, scripted routines. One of the key barriers is the lack of motion planning algorithms that can provide verifiable guarantees for safety, efficiency and reliability. To address this, a family of algorithms called Constant-Time Motion Planning (CTMP) was introduced, which leverages a preprocessing phase to enable collision-free motion queries in a fixed, user-specified time budget (e.g., 10 milliseconds). However, existing CTMP methods do not explicitly incorporate the manipulation behaviors essential for object handling. To bridge this gap, we introduce the \\textit{Behavioral Constant-Time Motion Planner} (B-CTMP), an algorithm that extends CTMP to solve a broad class of two-step manipulation tasks: (1) a collision-free motion to a behavior initiation state, followed by (2) execution of a manipulation behavior (such as grasping or insertion) to reach the goal. By precomputing compact data structures, B-CTMP guarantees constant-time query in mere milliseconds while ensuring completeness and successful task execution over a specified set of states. We evaluate B-CTMP on two canonical manipulation tasks in simulation, shelf picking and plug insertion,and demonstrate its effectiveness on a real robot. Our results show that B-CTMP unifies collision-free planning and object manipulation within a single constant-time framework, providing provable guarantees of speed and success for manipulation in semi-structured environments.",
    "published": "2025-11-30",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00939v1"
  },
  {
    "id": "2512.00938v1",
    "title": "DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics",
    "authors": [
      "Ahmed Mustafa Younes"
    ],
    "summary": "Transformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance.\n  We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions.\n  The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the \"what,\" \"how,\" and \"why\" behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00938v1"
  },
  {
    "id": "2512.00931v1",
    "title": "Mitigating Hallucinations in Zero-Shot Scientific Summarisation: A Pilot Study",
    "authors": [
      "Imane Jaaouine",
      "Ross D. King"
    ],
    "summary": "Large language models (LLMs) produce context inconsistency hallucinations, which are LLM generated outputs that are misaligned with the user prompt. This research project investigates whether prompt engineering (PE) methods can mitigate context inconsistency hallucinations in zero-shot LLM summarisation of scientific texts, where zero-shot indicates that the LLM relies purely on its pre-training data. Across eight yeast biotechnology research paper abstracts, six instruction-tuned LLMs were prompted with seven methods: a base- line prompt, two levels of increasing instruction complexity (PE-1 and PE-2), two levels of context repetition (CR-K1 and CR-K2), and two levels of random addition (RA-K1 and RA-K2). Context repetition involved the identification and repetition of K key sentences from the abstract, whereas random addition involved the repetition of K randomly selected sentences from the abstract, where K is 1 or 2. A total of 336 LLM-generated summaries were evaluated using six metrics: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, METEOR, and cosine similarity, which were used to compute the lexical and semantic alignment be- tween the summaries and the abstracts. Four hypotheses on the effects of prompt methods on summary alignment with the reference text were tested. Statistical analysis on 3744 collected datapoints was performed using bias-corrected and accelerated (BCa) bootstrap confidence intervals and Wilcoxon signed-rank tests with Bonferroni-Holm correction. The results demonstrated that CR and RA significantly improve the lexical alignment of LLM-generated summaries with the abstracts. These findings indicate that prompt engineering has the potential to impact hallucinations in zero-shot scientific summarisation tasks.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00931v1"
  },
  {
    "id": "2512.00918v1",
    "title": "Minimal neuron ablation triggers catastrophic collapse in the language core of Large Vision-Language Models",
    "authors": [
      "Cen Lu",
      "Yung-Chen Tang",
      "Andrea Cavallaro"
    ],
    "summary": "Large Vision-Language Models (LVLMs) have shown impressive multimodal understanding capabilities, yet their robustness is poorly understood. In this paper, we investigate the structural vulnerabilities of LVLMs to identify any critical neurons whose removal triggers catastrophic collapse. In this context, we propose CAN, a method to detect Consistently Activated Neurons and to locate critical neurons by progressive masking. Experiments on LLaVA-1.5-7b-hf and InstructBLIP-Vicuna-7b reveal that masking only a tiny portion of the language model's feed-forward networks (just as few as four neurons in extreme cases) suffices to trigger catastrophic collapse. Notably, critical neurons are predominantly localized in the language model rather than in the vision components, and the down-projection layer is a particularly vulnerable structure. We also observe a consistent two-stage collapse pattern: initial expressive degradation followed by sudden, complete collapse. Our findings provide important insights for safety research in LVLMs.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00918v1"
  },
  {
    "id": "2512.00912v1",
    "title": "ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices",
    "authors": [
      "Abdelghafour Halimi",
      "Ali Alibrahim",
      "Didier Barradas-Bautista",
      "Ronell Sicat",
      "Abdulkader M. Afifi"
    ],
    "summary": "This study presents a comprehensive deep learning pipeline for the automated classification of 12 foraminifera species using 2D micro-CT slices derived from 3D scans. We curated a scientifically rigorous dataset comprising 97 micro-CT scanned specimens across 27 species, selecting 12 species with sufficient representation for robust machine learning. To ensure methodological integrity and prevent data leakage, we employed specimen-level data splitting, resulting in 109,617 high-quality 2D slices (44,103 for training, 14,046 for validation, and 51,468 for testing). We evaluated seven state-of-the-art 2D convolutional neural network (CNN) architectures using transfer learning. Our final ensemble model, combining ConvNeXt-Large and EfficientNetV2-Small, achieved a test accuracy of 95.64%, with a top-3 accuracy of 99.6% and an area under the ROC curve (AUC) of 0.998 across all species. To facilitate practical deployment, we developed an interactive advanced dashboard that supports real-time slice classification and 3D slice matching using advanced similarity metrics, including SSIM, NCC, and the Dice coefficient. This work establishes new benchmarks for AI-assisted micropaleontological identification and provides a fully reproducible framework for foraminifera classification research, bridging the gap between deep learning and applied geosciences.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00912v1"
  },
  {
    "id": "2512.00908v1",
    "title": "Beyond High-Entropy Exploration: Correctness-Aware Low-Entropy Segment-Based Advantage Shaping for Reasoning LLMs",
    "authors": [
      "Xinzhu Chen",
      "Xuesheng Li",
      "Zhongxiang Sun",
      "Weijie Yu"
    ],
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a central approach for improving the reasoning ability of large language models. Recent work studies RLVR through token entropy, arguing that high-entropy tokens drive exploration and should receive stronger updates. However, they overlook the fact that most of a reasoning trajectory consists of low-entropy segments that encode stable and reusable structural patterns. Through qualitative and quantitative analyses, we find that the overlap of low-entropy segments across correct responses strongly correlates with model accuracy, while overlaps involving incorrect responses exhibit stable but unproductive patterns. Motivated by these findings, we propose LESS, a correctness-aware reinforcement framework that performs fine-grained advantage modulation over low-entropy segments. LESS amplifies segments unique to correct responses, suppresses those unique to incorrect ones, and neutralizes segments shared by both, while preserving high-entropy exploration in the underlying RL algorithm. Instantiated on top of the popular GRPO, LESS consistently improves accuracy over strong RL baselines across three backbones and six math benchmarks, achieves stronger robustness of the performance floor.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00908v1"
  },
  {
    "id": "2512.00888v1",
    "title": "Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models",
    "authors": [
      "Aayam Bansal",
      "Ishaan Gangwani"
    ],
    "summary": "Zero-shot foundation models (FMs) promise training-free prediction on tabular data, yet their hardware footprint remains poorly characterized. We present a fully reproducible benchmark that reports test accuracy together with wall-clock latency, peak CPU RAM, and peak GPU VRAM on four public datasets: Adult-Income, Higgs-100k, Wine-Quality, and California-Housing. Two open FMs (TabPFN-1.0 and TabICL-base) are compared against tuned XGBoost, LightGBM, and Random Forest baselines on a single NVIDIA T4 GPU. The tree ensembles equal or surpass FM accuracy on three datasets while completing full-test batches in <= 0.40 s and <= 150 MB RAM, using zero VRAM. TabICL achieves a 0.8 percentage-point gain on Higgs but requires roughly 40,000 times more latency (960 s) and 9 GB VRAM. TabPFN matches tree-model accuracy on Wine and Housing but peaks at 4 GB VRAM and cannot process the full 100k-row Higgs table. These results quantify the substantial hardware-versus-accuracy trade-offs in current tabular FMs and provide an open baseline for future efficiency-oriented research.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00888v1"
  },
  {
    "id": "2512.00882v1",
    "title": "Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints",
    "authors": [
      "Xisheng Feng"
    ],
    "summary": "Vision-Language Models (VLMs) exhibit significant performance plateaus in specialized domains like precision agriculture, primarily due to \"Reasoning-Driven Hallucination\" where linguistic priors override visual perception. A key bottleneck is the \"Modality Gap\": visual embeddings fail to reliably activate the fine-grained expert knowledge already encoded in model parameters. We propose \"Look, Recite, Then Answer,\" a parameter-efficient framework that enhances VLMs via self-generated knowledge hints while keeping backbone models frozen. The framework decouples inference into three stages: (1) Look generates objective visual descriptions and candidate sets; (2) Recite employs a lightweight 1.7B router to transform visual cues into targeted queries that trigger candidate-specific parametric knowledge; (3) Answer performs parallel evidence alignment between descriptions and recited knowledge to select the most consistent label. On AgroBench, our method achieves state-of-the-art results, improving Weed Identification accuracy by 23.6% over Qwen-VL and surpassing GPT-4o without external search overhead. This modular design mitigates hallucinations by transforming passive perception into active, controllable knowledge retrieval",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00882v1"
  },
  {
    "id": "2512.00881v1",
    "title": "Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing",
    "authors": [
      "Li Yuan",
      "Qingfei Huang",
      "Bingshan Zhu",
      "Yi Cai",
      "Qingbao Huang",
      "Changmeng Zheng",
      "Zikun Deng",
      "Tao Wang"
    ],
    "summary": "Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00881v1"
  },
  {
    "id": "2512.00878v1",
    "title": "Less is More: Resource-Efficient Low-Rank Adaptation",
    "authors": [
      "Chunlin Tian",
      "Xuyang Wei",
      "Huanrong Liu",
      "Zhijiang Guo",
      "Li Li"
    ],
    "summary": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), but it still incurs notable overhead and suffers from parameter interference in complex datasets. While re- cent works decouple LoRA update matrices to exploit matrix-wise asymmetry, training costs remain high. We revisit LoRA from the perspective of inter-matrix and intra-layer parameter redundancy and propose Resource-Efficient Low-Rank Adaptation, EffiLoRA, a lightweight and generalizable approach for language, multimodal, and diffusion models. EffiLoRA employs a unified A matrix across all transformer layers and introduces a runtime selective B matrices up- date to dynamically trade-off the system resource budget and model performance. EffiLoRA consistently outperforms LoRA across diverse modalities, including commonsense reasoning, visual instruction tuning, and image generation, demon- strating improved efficiency and robustness.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00878v1"
  },
  {
    "id": "2512.00872v1",
    "title": "TAP-CT: 3D Task-Agnostic Pretraining of Computed Tomography Foundation Models",
    "authors": [
      "Tim Veenboer",
      "George Yiasemis",
      "Eric Marcus",
      "Vivien Van Veldhuizen",
      "Cees G. M. Snoek",
      "Jonas Teuwen",
      "Kevin B. W. Groot Lipman"
    ],
    "summary": "Existing foundation models (FMs) in the medical domain often require extensive fine-tuning or rely on training resource-intensive decoders, while many existing encoders are pretrained with objectives biased toward specific tasks. This illustrates a need for a strong, task-agnostic foundation model that requires minimal fine-tuning beyond feature extraction. In this work, we introduce a suite of task-agnostic pretraining of CT foundation models (TAP-CT): a simple yet effective adaptation of Vision Transformers (ViTs) and DINOv2 for volumetric data, enabling scalable self-supervised pretraining directly on 3D CT volumes. Our approach incorporates targeted modifications to patch embeddings, positional encodings, and volumetric augmentations, making the architecture depth-aware while preserving the simplicity of the underlying architectures. We show that large-scale 3D pretraining on an extensive in-house CT dataset (105K volumes) yields stable, robust frozen representations that generalize strongly across downstream tasks. To promote transparency and reproducibility, and to establish a powerful, low-resource baseline for future research in medical imaging, we will release all pretrained models, experimental configurations, and downstream benchmark code at https://huggingface.co/fomofo/tap-ct-b-3d.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00872v1"
  },
  {
    "id": "2512.00862v1",
    "title": "HBLLM: Wavelet-Enhanced High-Fidelity 1-Bit Quantization for LLMs",
    "authors": [
      "Ningning Chen",
      "Weicai Ye",
      "Ying Jiang"
    ],
    "summary": "We introduce HBLLM, a wavelet-enhanced high-fidelity $1$-bit post-training quantization method for Large Language Models (LLMs). By leveraging Haar wavelet transforms to enhance expressive capacity through frequency decomposition, HBLLM significantly improves quantization fidelity while maintaining minimal overhead. This approach features two innovative structure-aware grouping strategies: (1) frequency-aware multi-parameter intra-row grouping and (2) $\\ell_2$-norm-based saliency-driven column selection. For non-salient weights, a shared mean is employed across quantization groups within each frequency band to optimize storage efficiency. Experiments conducted on the OPT and LLaMA models demonstrate that HBLLM achieves state-of-the-art performance in $1$-bit quantization, attaining a perplexity of $6.71$ on LLaMA$2$-$13$B with an average weight storage of only $1.08$ bits. Code available at: https://github.com/Yeyke/HBLLM.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00862v1"
  },
  {
    "id": "2512.00852v1",
    "title": "One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces",
    "authors": [
      "Yandong Sun",
      "Qiang Huang",
      "Ziwei Xu",
      "Yiqun Sun",
      "Yixuan Tang",
      "Anthony K. H. Tung"
    ],
    "summary": "Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00852v1"
  },
  {
    "id": "2512.00849v1",
    "title": "Topological Federated Clustering via Gravitational Potential Fields under Local Differential Privacy",
    "authors": [
      "Yunbo Long",
      "Jiaquan Zhang",
      "Xi Chen",
      "Alexandra Brintrup"
    ],
    "summary": "Clustering non-independent and identically distributed (non-IID) data under local differential privacy (LDP) in federated settings presents a critical challenge: preserving privacy while maintaining accuracy without iterative communication. Existing one-shot methods rely on unstable pairwise centroid distances or neighborhood rankings, degrading severely under strong LDP noise and data heterogeneity. We present Gravitational Federated Clustering (GFC), a novel approach to privacy-preserving federated clustering that overcomes the limitations of distance-based methods under varying LDP. Addressing the critical challenge of clustering non-IID data with diverse privacy guarantees, GFC transforms privatized client centroids into a global gravitational potential field where true cluster centers emerge as topologically persistent singularities. Our framework introduces two key innovations: (1) a client-side compactness-aware perturbation mechanism that encodes local cluster geometry as \"mass\" values, and (2) a server-side topological aggregation phase that extracts stable centroids through persistent homology analysis of the potential field's superlevel sets. Theoretically, we establish a closed-form bound between the privacy budget $ε$ and centroid estimation error, proving the potential field's Lipschitz smoothing properties exponentially suppress noise in high-density regions. Empirically, GFC outperforms state-of-the-art methods on ten benchmarks, especially under strong LDP constraints ($ε< 1$), while maintaining comparable performance at lower privacy budgets. By reformulating federated clustering as a topological persistence problem in a synthetic physics-inspired space, GFC achieves unprecedented privacy-accuracy trade-offs without iterative communication, providing a new perspective for privacy-preserving distributed learning.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00849v1"
  },
  {
    "id": "2512.00839v1",
    "title": "ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI",
    "authors": [
      "Fabrizio Maturo",
      "Donato Riccio",
      "Andrea Mazzitelli",
      "Giuseppe Bifulco",
      "Francesco Paolone",
      "Iulia Brezeanu"
    ],
    "summary": "This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "stat.CO",
      "stat.ME"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00839v1"
  },
  {
    "id": "2512.00836v1",
    "title": "Assessing model error in counterfactual worlds",
    "authors": [
      "Emily Howerton",
      "Justin Lessler"
    ],
    "summary": "Counterfactual scenario modeling exercises that ask \"what would happen if?\" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00836v1"
  },
  {
    "id": "2512.00834v1",
    "title": "SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks",
    "authors": [
      "Lin Zhu",
      "Kezhi Wang",
      "Luping Xiang",
      "Kun Yang"
    ],
    "summary": "Efficient information exchange and reliable contextual reasoning are essential for vehicle-to-everything (V2X) networks. Conventional communication schemes often incur significant transmission overhead and latency, while existing trajectory prediction models generally lack environmental perception and logical inference capabilities. This paper presents a trajectory prediction framework that integrates semantic communication with Agentic AI to enhance predictive performance in vehicular environments. In vehicle-to-infrastructure (V2I) communication, a feature-extraction agent at the Roadside Unit (RSU) derives compact representations from historical vehicle trajectories, followed by semantic reasoning performed by a semantic-analysis agent. The RSU then transmits both feature representations and semantic insights to the target vehicle via semantic communication, enabling the vehicle to predict future trajectories by combining received semantics with its own historical data. In vehicle-to-vehicle (V2V) communication, each vehicle performs local feature extraction and semantic analysis while receiving predicted trajectories from neighboring vehicles, and jointly utilizes this information for its own trajectory prediction. Extensive experiments across diverse communication conditions demonstrate that the proposed method significantly outperforms baseline schemes, achieving up to a 47.5% improvement in prediction accuracy under low signal-to-noise ratio (SNR) conditions.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00834v1"
  },
  {
    "id": "2512.00829v1",
    "title": "Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy",
    "authors": [
      "Md Mehrab Hossain Opi",
      "Sumaiya Khan",
      "Moshammad Farzana Rahman"
    ],
    "summary": "Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP's potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.",
    "published": "2025-11-30",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00829v1"
  },
  {
    "id": "2512.00818v1",
    "title": "Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning",
    "authors": [
      "Haozhen Gong",
      "Xiaozhong Ji",
      "Yuansen Liu",
      "Wenbin Wu",
      "Xiaoxiao Yan",
      "Jingjing Liu",
      "Kai Wu",
      "Jiazhen Pan",
      "Bailiang Jian",
      "Jiangning Zhang",
      "Xiaobin Hu",
      "Hongwei Bran Li"
    ],
    "summary": "MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00818v1"
  },
  {
    "id": "2512.00812v1",
    "title": "Causal Invariance and Counterfactual Learning Driven Cooperative Game for Multi-Label Classification",
    "authors": [
      "Yijia Fan",
      "Jusheng Zhang",
      "Kaitong Cai",
      "Jing Yang",
      "Keze Wang"
    ],
    "summary": "Multi-label classification (MLC) remains vulnerable to label imbalance, spurious correlations, and distribution shifts, challenges that are particularly detrimental to rare label prediction. To address these limitations, we introduce the Causal Cooperative Game (CCG) framework, which conceptualizes MLC as a cooperative multi-player interaction. CCG unifies explicit causal discovery via Neural Structural Equation Models with a counterfactual curiosity reward to drive robust feature learning. Furthermore, it incorporates a causal invariance loss to ensure generalization across diverse environments, complemented by a specialized enhancement strategy for rare labels. Extensive benchmarking demonstrates that CCG substantially outperforms strong baselines in both rare label prediction and overall robustness. Through rigorous ablation studies and qualitative analysis, we validate the efficacy and interpretability of our components, underscoring the potential of synergizing causal inference with cooperative game theory for advancing multi-label learning.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00812v1"
  },
  {
    "id": "2512.00807v1",
    "title": "BioPro: On Difference-Aware Gender Fairness for Vision-Language Models",
    "authors": [
      "Yujie Lin",
      "Jiayao Ma",
      "Qingguo Hu",
      "Derek F. Wong",
      "Jinsong Su"
    ],
    "summary": "Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00807v1"
  },
  {
    "id": "2512.00804v1",
    "title": "Bias Injection Attacks on RAG Databases and Sanitization Defenses",
    "authors": [
      "Hao Wu",
      "Prateek Saxena"
    ],
    "summary": "This paper explores attacks and defenses on vector databases in retrieval-augmented generation (RAG) systems. Prior work on knowledge poisoning attacks primarily inject false or toxic content, which fact-checking or linguistic analysis easily detects. We reveal a new and subtle threat: bias injection attacks, which insert factually correct yet semantically biased passages into the knowledge base to covertly influence the ideological framing of answers generated by large language models (LLMs). We demonstrate that these adversarial passages, though linguistically coherent and truthful, can systematically crowd out opposing views from the retrieved context and steer LLM answers toward the attacker's intended perspective.\n  We precisely characterize this class of attacks and then develop a post-retrieval filtering defense, BiasDef. We construct a comprehensive benchmark based on public question answering datasets to evaluate them. Our results show that: (1) the proposed attack induces significant perspective shifts in LLM answers, effectively evading existing retrieval-based sanitization defenses; and (2) BiasDef outperforms existing methods by reducing adversarial passages retrieved by 15\\% which mitigates perspective shift by 6.2\\times in answers, while enabling the retrieval of 62\\% more benign passages.",
    "published": "2025-11-30",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DB"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00804v1"
  },
  {
    "id": "2512.00791v1",
    "title": "Limitations of Using Identical Distributions for Training and Testing When Learning Boolean Functions",
    "authors": [
      "Jordi Pérez-Guijarro"
    ],
    "summary": "When the distributions of the training and test data do not coincide, the problem of understanding generalization becomes considerably more complex, prompting a variety of questions. In this work, we focus on a fundamental one: Is it always optimal for the training distribution to be identical to the test distribution? Surprisingly, assuming the existence of one-way functions, we find that the answer is no. That is, matching distributions is not always the best scenario, which contrasts with the behavior of most learning methods. Nonetheless, we also show that when certain regularities are imposed on the target functions, the standard conclusion is recovered in the case of the uniform distribution.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00791v1"
  },
  {
    "id": "2512.00772v1",
    "title": "SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG",
    "authors": [
      "Hyunseok Ryu",
      "Wonjune Shin",
      "Hyun Park"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language\n  Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to\n  construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing\n  speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.\n  Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of\n  Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a\n  Large Language Model as a Query Strategist to automatically transform unstructured natural language queries\n  into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process\n  of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual\n  embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual\n  dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,\n  combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and\n  reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,\n  presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.",
    "published": "2025-11-30",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00772v1"
  },
  {
    "id": "2512.00771v1",
    "title": "EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes",
    "authors": [
      "Xiaoshan Wu",
      "Yifei Yu",
      "Xiaoyang Lyu",
      "Yihua Huang",
      "Bo Wang",
      "Baoheng Zhang",
      "Zhongrui Wang",
      "Xiaojuan Qi"
    ],
    "summary": "Robust 3D geometry estimation from videos is critical for applications such as autonomous navigation, SLAM, and 3D scene reconstruction. Recent methods like DUSt3R demonstrate that regressing dense pointmaps from image pairs enables accurate and efficient pose-free reconstruction. However, existing RGB-only approaches struggle under real-world conditions involving dynamic objects and extreme illumination, due to the inherent limitations of conventional cameras. In this paper, we propose EAG3R, a novel geometry estimation framework that augments pointmap-based reconstruction with asynchronous event streams. Built upon the MonST3R backbone, EAG3R introduces two key innovations: (1) a retinex-inspired image enhancement module and a lightweight event adapter with SNR-aware fusion mechanism that adaptively combines RGB and event features based on local reliability; and (2) a novel event-based photometric consistency loss that reinforces spatiotemporal coherence during global optimization. Our method enables robust geometry estimation in challenging dynamic low-light scenes without requiring retraining on night-time data. Extensive experiments demonstrate that EAG3R significantly outperforms state-of-the-art RGB-only baselines across monocular depth estimation, camera pose tracking, and dynamic reconstruction tasks.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00771v1"
  },
  {
    "id": "2512.00763v1",
    "title": "Provable Benefit of Sign Descent: A Minimal Model Under Heavy-Tailed Class Imbalance",
    "authors": [
      "Robin Yadav",
      "Shuo Xie",
      "Tianhao Wang",
      "Zhiyuan Li"
    ],
    "summary": "Adaptive optimization methods (such as Adam) play a major role in LLM pretraining, significantly outperforming Gradient Descent (GD). Recent studies have proposed new smoothness assumptions on the loss function to explain the advantages of adaptive algorithms with structured preconditioners, e.g., coordinate-wise or layer-wise, and steepest descent methods w.r.t. non-euclidean norms, e.g., $\\ell_\\infty$ norm or spectral norm, over GD. However, it remains unclear how these smoothness assumptions manifest in language modelling tasks. In this work, we aim to analyze the benefit of $\\ell_\\infty$-norm descent (a.k.a. sign descent) directly from properties of the data distribution, namely, heavy-tailed class imbalance. We propose a minimal yet representative setting of next-token prediction, where we can provably show faster convergence of coordinate-wise algorithms such as Sign descent (steepest descent w.r.t. $\\ell_\\infty$ norm) over normalized GD (steepest descent w.r.t. to $\\ell_2$ norm) in the presence of heavy tail class imbalance.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00763v1"
  },
  {
    "id": "2512.00757v1",
    "title": "Preventing Model Collapse via Contraction-Conditioned Neural Filters",
    "authors": [
      "Zongjian Han",
      "Yiran Liang",
      "Ruiwen Wang",
      "Yiwei Luo",
      "Yilin Huang",
      "Xiaotong Song",
      "Dongqing Wei"
    ],
    "summary": "This paper presents a neural network filter method based on contraction operators to address model collapse in recursive training of generative models. Unlike \\cite{xu2024probabilistic}, which requires superlinear sample growth ($O(t^{1+s})$), our approach completely eliminates the dependence on increasing sample sizes within an unbiased estimation framework by designing a neural filter that learns to satisfy contraction conditions. We develop specialized neural network architectures and loss functions that enable the filter to actively learn contraction conditions satisfying Assumption 2.3 in exponential family distributions, thereby ensuring practical application of our theoretical results. Theoretical analysis demonstrates that when the learned contraction conditions are satisfied, estimation errors converge probabilistically even with constant sample sizes, i.e., $\\limsup_{t\\to\\infty}\\mathbb{P}(\\|\\mathbf{e}_t\\|>δ)=0$ for any $δ>0$. Experimental results show that our neural network filter effectively learns contraction conditions and prevents model collapse under fixed sample size settings, providing an end-to-end solution for practical applications.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00757v1"
  },
  {
    "id": "2512.00756v1",
    "title": "MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents",
    "authors": [
      "Ruihan Chen",
      "Qiming Li",
      "Xiaocheng Feng",
      "Xiaoliang Yang",
      "Weihong Zhong",
      "Yuxuan Gu",
      "Zekun Zhou",
      "Bing Qin"
    ],
    "summary": "With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements' spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents' P&R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents' multilingual P&R capability by 6.5% on average.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00756v1"
  },
  {
    "id": "2512.00748v1",
    "title": "Probabilistic Modeling of Multi-rater Medical Image Segmentation for Diversity and Personalization",
    "authors": [
      "Ke Liu",
      "Shangde Gao",
      "Yichao Fu",
      "Shangqi Gao",
      "Chunhua Shen"
    ],
    "summary": "Medical image segmentation is inherently influenced by data uncertainty, arising from ambiguous boundaries in medical scans and inter-observer variability in diagnosis. To address this challenge, previous works formulated the multi-rater medical image segmentation task, where multiple experts provide separate annotations for each image. However, existing models are typically constrained to either generate diverse segmentation that lacks expert specificity or to produce personalized outputs that merely replicate individual annotators. We propose Probabilistic modeling of multi-rater medical image Segmentation (ProSeg) that simultaneously enables both diversification and personalization. Specifically, we introduce two latent variables to model expert annotation preferences and image boundary ambiguity. Their conditional probabilistic distributions are then obtained through variational inference, allowing segmentation outputs to be generated by sampling from these distributions. Extensive experiments on both the nasopharyngeal carcinoma dataset (NPC) and the lung nodule dataset (LIDC-IDRI) demonstrate that our ProSeg achieves a new state-of-the-art performance, providing segmentation results that are both diverse and expert-personalized. Code can be found in https://github.com/AI4MOL/ProSeg.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00748v1"
  },
  {
    "id": "2512.00742v1",
    "title": "On the Regulatory Potential of User Interfaces for AI Agent Governance",
    "authors": [
      "K. J. Kevin Feng",
      "Tae Soo Kim",
      "Rock Yuren Pang",
      "Faria Huq",
      "Tal August",
      "Amy X. Zhang"
    ],
    "summary": "AI agents that take actions in their environment autonomously over extended time horizons require robust governance interventions to curb their potentially consequential risks. Prior proposals for governing AI agents primarily target system-level safeguards (e.g., prompt injection monitors) or agent infrastructure (e.g., agent IDs). In this work, we explore a complementary approach: regulating user interfaces of AI agents as a way of enforcing transparency and behavioral requirements that then demand changes at the system and/or infrastructure levels. Specifically, we analyze 22 existing agentic systems to identify UI elements that play key roles in human-agent interaction and communication. We then synthesize those elements into six high-level interaction design patterns that hold regulatory potential (e.g., requiring agent memory to be editable). We conclude with policy recommendations based on our analysis. Our work exposes a new surface for regulatory action that supplements previous proposals for practical AI agent governance.",
    "published": "2025-11-30",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00742v1"
  },
  {
    "id": "2512.00741v1",
    "title": "MASCOT: Analyzing Malware Evolution Through A Well-Curated Source Code Dataset",
    "authors": [
      "Bojing Li",
      "Duo Zhong",
      "Dharani Nadendla",
      "Gabriel Terceros",
      "Prajna Bhandar",
      "Raguvir S",
      "Charles Nicholas"
    ],
    "summary": "In recent years, the explosion of malware and extensive code reuse have formed complex evolutionary connections among malware specimens. The rapid pace of development makes it challenging for existing studies to characterize recent evolutionary trends. In addition, intuitive tools to untangle these intricate connections between malware specimens or categories are urgently needed. This paper introduces a manually-reviewed malware source code dataset containing 6032 specimens. Building on and extending current research from a software engineering perspective, we systematically evaluate the scale, development costs, code quality, as well as security and dependencies of modern malware. We further introduce a multi-view genealogy analysis to clarify malware connections: at an overall view, this analysis quantifies the strength and direction of connections among specimens and categories; at a detailed view, it traces the evolutionary histories of individual specimens. Experimental results indicate that, despite persistent shortcomings in code quality, malware specimens exhibit an increasing complexity and standardization, in step with the development of mainstream software engineering practices. Meanwhile, our genealogy analysis intuitively reveals lineage expansion and evolution driven by code reuse, providing new evidence and tools for understanding the formation and evolution of the malware ecosystem.",
    "published": "2025-11-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00741v1"
  },
  {
    "id": "2512.00738v1",
    "title": "Orchestrating Rewards in the Era of Intelligence-Driven Commerce",
    "authors": [
      "Paul Osemudiame Oamen",
      "Robert Wesley",
      "Pius Onobhayedo"
    ],
    "summary": "Despite their evolution from early copper-token schemes to sophisticated digital solutions, loyalty programs remain predominantly closed ecosystems, with brands retaining full control over all components. Coalition loyalty programs emerged to enable cross-brand interoperability, but approximately 60\\% fail within 10 years in spite of theoretical advantages rooted in network economics. This paper demonstrates that coalition failures stem from fundamental architectural limitations in centralized operator models rather than operational deficiencies, and argues further that neither closed nor coalition systems can scale in intelligence-driven paradigms where AI agents mediate commerce and demand trustless, protocol-based coordination that existing architectures cannot provide. We propose a hybrid framework where brands maintain sovereign control over their programs while enabling cross-brand interoperability through trustless exchange mechanisms. Our framework preserves closed system advantages while enabling open system benefits without the structural problems that doom traditional coalitions. We derive a mathematical pricing model accounting for empirically-validated market factors while enabling fair value exchange across interoperable reward systems.",
    "published": "2025-11-30",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00738v1"
  },
  {
    "id": "2512.00736v1",
    "title": "REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories",
    "authors": [
      "Jacob Thompson",
      "Emiliano Garcia-Lopez",
      "Yonatan Bisk"
    ],
    "summary": "Humans build viewpoint-independent cognitive maps through navigation, enabling intuitive reasoning about object permanence and spatial relations. We argue that multimodal large language models (MLLMs), despite extensive video training, lack this fundamental spatial reasoning capability, a critical limitation for embodied applications. To demonstrate these limitations and drive research, we introduce REM (Reasoning over Embodied Multi-Frame Trajectories), a benchmark using controllable 3D environments for long-horizon embodied spatial reasoning. REM systematically evaluates key aspects like object permanence/distinction, spatial relationships, and numerical tracking across dynamic embodied viewpoints. Our evaluation shows that the best-performing current models exhibit promising overall performance, but become increasingly unreliable at even moderate complexity levels easily handled by humans. These findings highlight challenges MLLMs face in developing robust spatial representations from sequential visual input. Consequently, REM provides targeted metrics and diagnostics to foster improved spatial understanding in future models.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00736v1"
  },
  {
    "id": "2512.00729v1",
    "title": "Probing the \"Psyche'' of Large Reasoning Models: Understanding Through a Human Lens",
    "authors": [
      "Yuxiang Chen",
      "Zuohan Wu",
      "Ziwei Wang",
      "Xiangning Yu",
      "Xujia Li",
      "Linyi Yang",
      "Mengyue Yang",
      "Jun Wang",
      "Lei Chen"
    ],
    "summary": "Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00729v1"
  },
  {
    "id": "2512.00728v1",
    "title": "Deep Learning for Modeling and Dispatching Hybrid Wind Farm Power Generation",
    "authors": [
      "Zach Lawrence",
      "Jessica Yao",
      "Chris Qin"
    ],
    "summary": "Wind farms with integrated energy storage, or hybrid wind farms, are able to store energy and dispatch it to the grid following an operational strategy. For individual wind farms with integrated energy storage capacity, data-driven dispatch strategies using localized grid demand and market conditions as input parameters stand to maximize wind energy value. Synthetic power generation data modeled on atmospheric conditions provide another avenue for improving the robustness of data-driven dispatch strategies. To these ends, the present work develops two deep learning frameworks: COVE-NN, an LSTM-based dispatch strategy tailored to individual wind farms, which reduced annual COVE by 32.3% over 43 years of simulated operations in a case study at the Pyron site; and a power generation modeling framework that reduced RMSE by 9.5% and improved power curve similarity by 18.9% when validated on the Palouse wind farm. Together, these models pave the way for more robust, data-driven dispatch strategies and potential extensions to other renewable energy systems.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00728v1"
  },
  {
    "id": "2512.00722v1",
    "title": "SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs",
    "authors": [
      "Jiaming Xu",
      "Jiayi Pan",
      "Hanzhen Wang",
      "Yongkang Zhou",
      "Jiancai Ye",
      "Yu Wang",
      "Guohao Dai"
    ],
    "summary": "In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00722v1"
  },
  {
    "id": "2512.00716v1",
    "title": "Graph Data Augmentation with Contrastive Learning on Covariate Distribution Shift",
    "authors": [
      "Fanlong Zeng",
      "Wensheng Gan"
    ],
    "summary": "Covariate distribution shift occurs when certain structural features present in the test set are absent from the training set. It is a common type of out-of-distribution (OOD) problem, frequently encountered in real-world graph data with complex structures. Existing research has revealed that most out-of-the-box graph neural networks (GNNs) fail to account for covariate shifts. Furthermore, we observe that existing methods aimed at addressing covariate shifts often fail to fully leverage the rich information contained within the latent space. Motivated by the potential of the latent space, we introduce a new method called MPAIACL for More Powerful Adversarial Invariant Augmentation using Contrastive Learning. MPAIACL leverages contrastive learning to unlock the full potential of vector representations by harnessing their intrinsic information. Through extensive experiments, MPAIACL demonstrates its robust generalization and effectiveness, as it performs well compared with other baselines across various public OOD datasets. The code is publicly available at https://github.com/flzeng1/MPAIACL.",
    "published": "2025-11-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00716v1"
  },
  {
    "id": "2512.00714v1",
    "title": "Deep Learning-Based Computer Vision Models for Early Cancer Detection Using Multimodal Medical Imaging and Radiogenomic Integration Frameworks",
    "authors": [
      "Emmanuella Avwerosuoghene Oghenekaro"
    ],
    "summary": "Early cancer detection remains one of the most critical challenges in modern healthcare, where delayed diagnosis significantly reduces survival outcomes. Recent advancements in artificial intelligence, particularly deep learning, have enabled transformative progress in medical imaging analysis. Deep learning-based computer vision models, such as convolutional neural networks (CNNs), transformers, and hybrid attention architectures, can automatically extract complex spatial, morphological, and temporal patterns from multimodal imaging data including MRI, CT, PET, mammography, histopathology, and ultrasound. These models surpass traditional radiological assessment by identifying subtle tissue abnormalities and tumor microenvironment variations invisible to the human eye. At a broader scale, the integration of multimodal imaging with radiogenomics linking quantitative imaging features with genomics, transcriptomics, and epigenetic biomarkers has introduced a new paradigm for personalized oncology. This radiogenomic fusion allows the prediction of tumor genotype, immune response, molecular subtypes, and treatment resistance without invasive biopsies.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00714v1"
  },
  {
    "id": "2512.00713v1",
    "title": "Concept-Guided Backdoor Attack on Vision Language Models",
    "authors": [
      "Haoyu Shen",
      "Weimin Lyu",
      "Haotian Xu",
      "Tengfei Ma"
    ],
    "summary": "Vision-Language Models (VLMs) have achieved impressive progress in multimodal text generation, yet their rapid adoption raises increasing concerns about security vulnerabilities. Existing backdoor attacks against VLMs primarily rely on explicit pixel-level triggers or imperceptible perturbations injected into images. While effective, these approaches reduce stealthiness and remain vulnerable to image-based defenses. We introduce concept-guided backdoor attacks, a new paradigm that operates at the semantic concept level rather than on raw pixels. We propose two different attacks. The first, Concept-Thresholding Poisoning (CTP), uses explicit concepts in natural images as triggers: only samples containing the target concept are poisoned, causing the model to behave normally in all other cases but consistently inject malicious outputs whenever the concept appears. The second, CBL-Guided Unseen Backdoor (CGUB), leverages a Concept Bottleneck Model (CBM) during training to intervene on internal concept activations, while discarding the CBM branch at inference time to keep the VLM unchanged. This design enables systematic replacement of a targeted label in generated text (for example, replacing \"cat\" with \"dog\"), even when the replacement behavior never appears in the training data. Experiments across multiple VLM architectures and datasets show that both CTP and CGUB achieve high attack success rates while maintaining moderate impact on clean-task performance. These findings highlight concept-level vulnerabilities as a critical new attack surface for VLMs.",
    "published": "2025-11-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00713v1"
  },
  {
    "id": "2512.00709v1",
    "title": "When Human Preferences Flip: An Instance-Dependent Robust Loss for RLHF",
    "authors": [
      "Yifan Xu",
      "Xichen Ye",
      "Yifan Chen",
      "Qiaosheng Zhang"
    ],
    "summary": "Quality of datasets plays an important role in large language model (LLM) alignment. In collecting human feedback, however, preference flipping is ubiquitous and causes corruption in data annotation; the issue necessitates the alignment algorithms with improved robustness against potential flipped pairs. To this end, this paper introduces a Flipping-Aware Direct Preference Optimization (FA-DPO) algorithm tailored to preference flipping from a reinforcement learning with human feedback (RLHF) perspective. We dissect the inherent human intention model and the preference flipping mechanism introduced by external factors as two distinct stages; in the latter, we introduce an instance-dependent flipping probability on the basis of the Bradley-Terry (BT) model. Further, by leveraging features relevant to preference annotation, we capture uncertainty in judgments and model preference flipping patterns. In practice, we design a simple yet efficient iterative optimization algorithm compatible with the original RLHF and DPO algorithms. In our experiments, we investigate the instance-dependent preference flipping model under multiple circumstances for evaluation of our proposed method, as well as other baseline methods.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00709v1"
  },
  {
    "id": "2512.00706v1",
    "title": "Optimizing LVLMs with On-Policy Data for Effective Hallucination Mitigation",
    "authors": [
      "Chengzhi Yu",
      "Yifan Xu",
      "Yifan Chen",
      "Wenyi Zhang"
    ],
    "summary": "Recently, large vision-language models (LVLMs) have risen to be a promising approach for multimodal tasks. However, principled hallucination mitigation remains a critical challenge.In this work, we first analyze the data generation process in LVLM hallucination mitigation and affirm that on-policy data significantly outperforms off-policy data, which thus calls for efficient and reliable preference annotation of on-policy data. We then point out that, existing annotation methods introduce additional hallucination in training samples, which may enhance the model's hallucination patterns, to address this problem, we propose training a hallucination classifier giving binary annotations, which guarantee clean chosen samples for the subsequent alignment. To further harness of the power of on-policy data, we design a robust iterative direct preference optimization (DPO) algorithm adopting a dynamic sample reweighting scheme. We conduct comprehensive experiments on three benchmarks with comparison to 8 state-of-the-art baselines. In particular, our approach reduces the hallucination rate of LLaVA-1.5-7B on MMHalBench by 50.8% and the average hallucination rate on Object HalBench by 79.5%; more significantly, our method fully taps into the potential of open-source models, enabling LLaVA-1.5-13B to even surpass the performance of GPT-4V.",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00706v1"
  },
  {
    "id": "2512.00696v1",
    "title": "Hierarchical Molecular Language Models (HMLMs)",
    "authors": [
      "Hasi Hays",
      "Yue Yu",
      "William Richardson"
    ],
    "summary": "Cellular signaling networks represent complex information processing systems that have been modeled via traditional mathematical or statistical approaches. However, these methods often struggle to capture context-dependent signaling, pathway cross-talk, and temporal dynamics across multiple biological scales. Here, we introduce hierarchical molecular language models (HMLMs), a novel architecture that proposes a molecular network-specific large language model (LLM) to use in intracellular communication as a specialized molecular language, which includes molecules as tokens, protein interactions, post-translational modifications, and regulatory events modeled as semantic relationships within an adapted transformer architecture. HMLMs employ graph-structured attention mechanisms to accommodate signaling network topology while integrating information across the molecular, pathway, and cellular scales through hierarchical attention patterns. We demonstrate HMLM superiority using a cardiac fibroblast signaling network comprising over 100 molecular species across functional modules connected by regulatory edges. HMLM achieved a mean squared error (MSE) of 0.058 for temporal signaling predictions, representing 30% improvement over graph neural networks (GNNs: 0.083) and 52% improvement over ordinary differential equation models (ODEs: 0.121), with particular advantages under sparse temporal sampling conditions where HMLM maintained MSE = 0.041 with only 4 time-points. The HMLMs offer a foundation for AI-driven biology and medicine with predictable scaling characteristics suitable for interactive applications. By bridging molecular mechanisms with cellular phenotypes through AI-driven molecular language representation, HMLMs provide a powerful paradigm for systems biology that advances precision medicine applications and therapeutic discovery in the era of AI.",
    "published": "2025-11-30",
    "categories": [
      "q-bio.MN",
      "cs.AI",
      "cs.ET"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00696v1"
  },
  {
    "id": "2512.00683v1",
    "title": "Model of human cognition",
    "authors": [
      "Wu Yonggang"
    ],
    "summary": "The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.",
    "published": "2025-11-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00683v1"
  },
  {
    "id": "2512.00677v1",
    "title": "Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer",
    "authors": [
      "Dong In Lee",
      "Hyungjun Doh",
      "Seunggeun Chi",
      "Runlin Duan",
      "Sangpil Kim",
      "Karthik Ramani"
    ],
    "summary": "Recent progress in 4D representations, such as Dynamic NeRF and 4D Gaussian Splatting (4DGS), has enabled dynamic 4D scene reconstruction. However, text-driven 4D scene editing remains under-explored due to the challenge of ensuring both multi-view and temporal consistency across space and time during editing. Existing studies rely on 2D diffusion models that edit frames independently, often causing motion distortion, geometric drift, and incomplete editing. We introduce Dynamic-eDiTor, a training-free text-driven 4D editing framework leveraging Multimodal Diffusion Transformer (MM-DiT) and 4DGS. This mechanism consists of Spatio-Temporal Sub-Grid Attention (STGA) for locally consistent cross-view and temporal fusion, and Context Token Propagation (CTP) for global propagation via token inheritance and optical-flow-guided token replacement. Together, these components allow Dynamic-eDiTor to perform seamless, globally consistent multi-view video without additional training and directly optimize pre-trained source 4DGS. Extensive experiments on multi-view video dataset DyNeRF demonstrate that our method achieves superior editing fidelity and both multi-view and temporal consistency prior approaches. Project page for results and code: https://di-lee.github.io/dynamic-eDiTor/",
    "published": "2025-11-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.00677v1"
  }
]